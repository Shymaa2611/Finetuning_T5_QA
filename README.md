## T5 (Question-Answering)
 - T5, or Text-to-Text Transfer Transformer, is a Transformer based architecture that uses a 
   text-to-text approach. Every task – including translation, question answering, and classification – is cast as feeding the model text as input and training it to generate some target text. This allows for the use of the same model, loss function, hyperparameters, etc. across our diverse set of tasks.



![T5](t5.jpg)

## Dataset
 - dataset is collection of books and slids that related with computer science and information 
   system fields . 


## FineTuning
 
## Technologies

 - python
 - torch
 - pytorch_lighting
 - transformers
 - scikit-learn


## Create dataset 
 - run create_data.ipynb

## Preprocessing
 - pip install data.py

## Train
 - git clone https://github.com/Shymaa2611/Finetuning_T5_QA.git
 - cd Finetuning_T5_QA
 - pip install -r requirements.txt
 - pip install data.py
 - pip install train.py


 ## Inference
